{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrdOettJxaCc"
   },
   "source": [
    "!bash ./datasets/download_cyclegan_dataset.sh horse2zebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# Pretrained models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B75UqtKhxznS"
   },
   "source": [
    "!bash ./scripts/download_cyclegan_model.sh horse2zebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/horse2zebra --name horse2zebra --model cycle_gan`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. I've found that a batch size of 16 fits onto 4 V100s and can finish training an epoch in ~90s.\n",
    "\n",
    "Once your model has trained, copy over the last checkpoint to a format that the testing model can automatically detect:\n",
    "\n",
    "Use `cp ./checkpoints/horse2zebra/latest_net_G_A.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class A to class B and `cp ./checkpoints/horse2zebra/latest_net_G_B.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class B to class A.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--continue_train --epoch_count 135\n",
    "unet_256\n",
    "resnet_9blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sp7TCT2x9dB",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/prueba             \t[default: None]\n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: -1                            \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                 lambda_A: 10.0                          \n",
      "                 lambda_B: 10.0                          \n",
      "          lambda_identity: 0.5                           \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: prueba_unpaired_resnet9_NCCT2ADC\t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "                  segroot: None                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gustavo_pupils/Gyss/trabajo_pregrado/pytorch-cyclegan-and-pix2pix/train.py\", line 33, in <module>\n",
      "    dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
      "  File \"/home/gustavo_pupils/Gyss/trabajo_pregrado/pytorch-cyclegan-and-pix2pix/data/__init__.py\", line 57, in create_dataset\n",
      "    data_loader = CustomDatasetDataLoader(opt)\n",
      "  File \"/home/gustavo_pupils/Gyss/trabajo_pregrado/pytorch-cyclegan-and-pix2pix/data/__init__.py\", line 73, in __init__\n",
      "    self.dataset = dataset_class(opt)\n",
      "  File \"/home/gustavo_pupils/Gyss/trabajo_pregrado/pytorch-cyclegan-and-pix2pix/data/unaligned_dataset.py\", line 29, in __init__\n",
      "    self.A_paths = sorted(make_dataset(self.dir_A, opt.max_dataset_size))   # load images from '/path/to/data/trainA'\n",
      "  File \"/home/gustavo_pupils/Gyss/trabajo_pregrado/pytorch-cyclegan-and-pix2pix/data/image_folder.py\", line 25, in make_dataset\n",
      "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
      "AssertionError: ./datasets/prueba/trainA is not a valid directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 189 / 200 \t Time Taken: 33 sec\n",
      "learning rate 0.0000218 -> 0.0000198\n",
      "(epoch: 190, iters: 94, time: 0.970, data: 0.001) D_A: 0.058 G_A: 0.498 cycle_A: 0.037 idt_A: 0.045 D_B: 0.082 G_B: 0.406 cycle_B: 0.166 idt_B: 0.012 \n",
      "saving the model at the end of epoch 190, iters 29260\n",
      "End of epoch 190 / 200 \t Time Taken: 34 sec\n",
      "learning rate 0.0000198 -> 0.0000178\n",
      "(epoch: 191, iters: 40, time: 0.227, data: 0.001) D_A: 0.075 G_A: 0.552 cycle_A: 0.265 idt_A: 0.059 D_B: 0.022 G_B: 0.826 cycle_B: 0.220 idt_B: 0.057 \n",
      "(epoch: 191, iters: 140, time: 0.228, data: 0.001) D_A: 0.039 G_A: 0.749 cycle_A: 0.083 idt_A: 0.054 D_B: 0.080 G_B: 0.530 cycle_B: 0.195 idt_B: 0.024 \n",
      "End of epoch 191 / 200 \t Time Taken: 33 sec\n",
      "learning rate 0.0000178 -> 0.0000158\n",
      "(epoch: 192, iters: 86, time: 0.231, data: 0.001) D_A: 0.048 G_A: 0.666 cycle_A: 0.172 idt_A: 0.077 D_B: 0.145 G_B: 0.545 cycle_B: 0.287 idt_B: 0.039 \n",
      "End of epoch 192 / 200 \t Time Taken: 33 sec\n",
      "learning rate 0.0000158 -> 0.0000139\n",
      "(epoch: 193, iters: 32, time: 0.956, data: 0.001) D_A: 0.026 G_A: 1.091 cycle_A: 0.256 idt_A: 0.104 D_B: 0.019 G_B: 0.766 cycle_B: 0.396 idt_B: 0.058 \n",
      "(epoch: 193, iters: 132, time: 0.232, data: 0.001) D_A: 0.096 G_A: 0.585 cycle_A: 0.291 idt_A: 0.031 D_B: 0.100 G_B: 0.795 cycle_B: 0.118 idt_B: 0.072 \n",
      "End of epoch 193 / 200 \t Time Taken: 33 sec\n",
      "learning rate 0.0000139 -> 0.0000119\n",
      "(epoch: 194, iters: 78, time: 0.231, data: 0.001) D_A: 0.036 G_A: 0.736 cycle_A: 0.236 idt_A: 0.043 D_B: 0.032 G_B: 0.757 cycle_B: 0.185 idt_B: 0.059 \n",
      "End of epoch 194 / 200 \t Time Taken: 33 sec\n",
      "learning rate 0.0000119 -> 0.0000099\n",
      "(epoch: 195, iters: 24, time: 0.232, data: 0.001) D_A: 0.020 G_A: 0.951 cycle_A: 0.208 idt_A: 0.039 D_B: 0.012 G_B: 0.611 cycle_B: 0.178 idt_B: 0.048 \n",
      "(epoch: 195, iters: 124, time: 0.883, data: 0.001) D_A: 0.045 G_A: 0.878 cycle_A: 0.266 idt_A: 0.080 D_B: 0.033 G_B: 0.475 cycle_B: 0.342 idt_B: 0.065 \n",
      "saving the latest model (epoch 195, total_iters 30000)\n",
      "saving the model at the end of epoch 195, iters 30030\n",
      "End of epoch 195 / 200 \t Time Taken: 34 sec\n",
      "learning rate 0.0000099 -> 0.0000079\n",
      "(epoch: 196, iters: 70, time: 0.231, data: 0.001) D_A: 0.080 G_A: 0.851 cycle_A: 0.253 idt_A: 0.039 D_B: 0.088 G_B: 0.467 cycle_B: 0.167 idt_B: 0.061 \n",
      "End of epoch 196 / 200 \t Time Taken: 33 sec\n",
      "learning rate 0.0000079 -> 0.0000059\n",
      "(epoch: 197, iters: 16, time: 0.232, data: 0.001) D_A: 0.045 G_A: 1.039 cycle_A: 0.241 idt_A: 0.068 D_B: 0.017 G_B: 1.032 cycle_B: 0.293 idt_B: 0.057 \n",
      "(epoch: 197, iters: 116, time: 0.228, data: 0.001) D_A: 0.062 G_A: 1.048 cycle_A: 0.269 idt_A: 0.081 D_B: 0.147 G_B: 0.555 cycle_B: 0.338 idt_B: 0.061 \n",
      "End of epoch 197 / 200 \t Time Taken: 33 sec\n",
      "learning rate 0.0000059 -> 0.0000040\n",
      "(epoch: 198, iters: 62, time: 0.948, data: 0.001) D_A: 0.036 G_A: 0.541 cycle_A: 0.057 idt_A: 0.036 D_B: 0.032 G_B: 0.945 cycle_B: 0.144 idt_B: 0.016 \n",
      "End of epoch 198 / 200 \t Time Taken: 33 sec\n",
      "learning rate 0.0000040 -> 0.0000020\n",
      "(epoch: 199, iters: 8, time: 0.230, data: 0.001) D_A: 0.090 G_A: 0.571 cycle_A: 0.095 idt_A: 0.043 D_B: 0.016 G_B: 0.428 cycle_B: 0.201 idt_B: 0.025 \n",
      "(epoch: 199, iters: 108, time: 0.230, data: 0.000) D_A: 0.055 G_A: 0.787 cycle_A: 0.292 idt_A: 0.045 D_B: 0.180 G_B: 0.522 cycle_B: 0.181 idt_B: 0.072 \n",
      "End of epoch 199 / 200 \t Time Taken: 33 sec\n",
      "learning rate 0.0000020 -> 0.0000000\n",
      "(epoch: 200, iters: 54, time: 0.230, data: 0.001) D_A: 0.033 G_A: 0.844 cycle_A: 0.055 idt_A: 0.062 D_B: 0.041 G_B: 0.723 cycle_B: 0.221 idt_B: 0.018 \n",
      "(epoch: 200, iters: 154, time: 0.985, data: 0.001) D_A: 0.042 G_A: 1.087 cycle_A: 0.262 idt_A: 0.086 D_B: 0.153 G_B: 0.877 cycle_B: 0.306 idt_B: 0.059 \n",
      "saving the model at the end of epoch 200, iters 30800\n",
      "End of epoch 200 / 200 \t Time Taken: 34 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/prueba --name prueba_unpaired_resnet9_NCCT2ADC --model cycle_gan --display_id -1 --netG resnet_9blocks --dataset_mode aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout`\n",
    "\n",
    "Change the `--dataroot` and `--name` to be consistent with your trained model's configuration.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> The option --model test is used for generating results of CycleGAN only for one side. This option will automatically set --dataset_mode single, which only loads the images from one set. On the contrary, using --model cycle_gan requires loading and generating results in both directions, which is sometimes unnecessary. The results will be saved at ./results/. Use --results_dir {directory_path_to_save_result} to specify the results directory.\n",
    "\n",
    "> For your own experiments, you might want to specify --netG, --norm, --no_dropout to match the generator architecture of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCsKkEq0yGh0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python test.py --dataroot datasets/prueba --name apis_unpaired_resnet9_NCCT2DWI --model cycle_gan --num_test 647 --netG resnet_9blocks --no_dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/horse2zebra_pretrained/test_latest/images/n02381460_1010_fake.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/horse2zebra_pretrained/test_latest/images/n02381460_1010_real.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CycleGAN",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
